{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T15:12:29.152861Z","iopub.execute_input":"2022-03-17T15:12:29.153494Z","iopub.status.idle":"2022-03-17T15:12:29.181265Z","shell.execute_reply.started":"2022-03-17T15:12:29.1534Z","shell.execute_reply":"2022-03-17T15:12:29.180547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport io\nimport cv2\nimport numpy as np\nfrom os import listdir\nfrom os.path import isfile, join\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications import ResNet50\n\nfrom keras import layers\nfrom keras.models import Model\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom skimage.feature import hog\nfrom skimage import data, exposure\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:14:23.99288Z","iopub.execute_input":"2022-03-17T15:14:23.993287Z","iopub.status.idle":"2022-03-17T15:14:24.001491Z","shell.execute_reply.started":"2022-03-17T15:14:23.993252Z","shell.execute_reply":"2022-03-17T15:14:24.000807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install keras_vggface\n# !pip install keras_applications \n# !pip install keras_preprocessing ","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:12:38.981332Z","iopub.execute_input":"2022-03-17T15:12:38.981657Z","iopub.status.idle":"2022-03-17T15:12:55.766039Z","shell.execute_reply.started":"2022-03-17T15:12:38.98162Z","shell.execute_reply":"2022-03-17T15:12:55.765205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install git+https://github.com/rcmalli/keras-vggface.git","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:12:55.769551Z","iopub.execute_input":"2022-03-17T15:12:55.769772Z","iopub.status.idle":"2022-03-17T15:13:07.142609Z","shell.execute_reply.started":"2022-03-17T15:12:55.769746Z","shell.execute_reply":"2022-03-17T15:13:07.141753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from keras_vggface.vggface import VGGFace\nfrom keras_vggface.utils import decode_predictions, preprocess_input","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:14:21.291928Z","iopub.execute_input":"2022-03-17T15:14:21.292199Z","iopub.status.idle":"2022-03-17T15:14:21.297321Z","shell.execute_reply.started":"2022-03-17T15:14:21.29217Z","shell.execute_reply":"2022-03-17T15:14:21.296507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:07:57.397722Z","iopub.execute_input":"2022-03-17T15:07:57.397973Z","iopub.status.idle":"2022-03-17T15:08:04.75578Z","shell.execute_reply.started":"2022-03-17T15:07:57.397944Z","shell.execute_reply":"2022-03-17T15:08:04.754965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\nimport random\nimport os\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:14:32.436216Z","iopub.execute_input":"2022-03-17T15:14:32.436827Z","iopub.status.idle":"2022-03-17T15:14:32.557259Z","shell.execute_reply.started":"2022-03-17T15:14:32.436787Z","shell.execute_reply":"2022-03-17T15:14:32.556542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseNetwork(tf.keras.Model):\n    def __init__(self, vgg_face):\n        super(SiameseNetwork, self).__init__()\n        self.vgg_face = vgg_face\n        \n    @tf.function\n    def call(self, inputs):\n        image_1, image_2, image_3 =  inputs\n        with tf.name_scope(\"Anchor\") as scope:\n            feature_1 = self.vgg_face(image_1)\n            feature_1 = tf.math.l2_normalize(feature_1, axis=-1)\n        with tf.name_scope(\"Positive\") as scope:\n            feature_2 = self.vgg_face(image_2)\n            feature_2 = tf.math.l2_normalize(feature_2, axis=-1)\n        with tf.name_scope(\"Negative\") as scope:\n            feature_3 = self.vgg_face(image_3)\n            feature_3 = tf.math.l2_normalize(feature_3, axis=-1)\n        return [feature_1, feature_2, feature_3]\n    \n    @tf.function\n    def get_features(self, inputs):\n        return tf.math.l2_normalize(self.vgg_face(inputs), axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:13:14.853074Z","iopub.execute_input":"2022-03-17T15:13:14.853387Z","iopub.status.idle":"2022-03-17T15:13:14.870004Z","shell.execute_reply.started":"2022-03-17T15:13:14.85335Z","shell.execute_reply":"2022-03-17T15:13:14.869191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, dataset_path, batch_size=20, shuffle=True):\n        self.dataset = self.curate_dataset(dataset_path)\n        self.dataset_path = dataset_path\n        self.shuffle = shuffle\n        self.batch_size =batch_size\n        self.no_of_people = len(list(self.dataset.keys()))\n        self.on_epoch_end()\n        #print(self.dataset.keys())\n        \n    def __getitem__(self, index):\n        people = list(self.dataset.keys())[index * self.batch_size: (index + 1) * self.batch_size]\n        P = []\n        A = []\n        N = []\n        \n        for person in people:\n            anchor_index = random.randint(0, len(self.dataset[person])-1)\n            a = self.get_image(person, anchor_index)\n            \n            positive_index = random.randint(0, len(self.dataset[person])-1)\n            while positive_index == anchor_index and len(self.dataset[person]) != 1:\n                positive_index = random.randint(0, len(self.dataset[person])-1)\n                \n            p = self.get_image(person, positive_index)\n            \n            negative_person_index = random.randint(0, self.no_of_people - 1)\n            negative_person = list(self.dataset.keys())[negative_person_index]\n            while negative_person == person:\n                negative_person_index = random.randint(0, self.no_of_people - 1)\n                negative_person = list(self.dataset.keys())[negative_person_index]\n            \n            negative_index = random.randint(0, len(self.dataset[negative_person])-1)\n            n = self.get_image(negative_person, negative_index)\n            P.append(p)\n            A.append(a)\n            N.append(n)\n        A = np.asarray(A)\n        N = np.asarray(N)\n        P = np.asarray(P)\n        return [A, P, N]\n        \n    def __len__(self):\n        return self.no_of_people // self.batch_size\n        \n    def curate_dataset(self, dataset_path):\n        dataset = {}\n        dirs = [dir for dir in listdir(dataset_path)]\n        for dir in dirs: \n            fichiers = [f for f in listdir(dataset_path+dir) if \"jpeg\" in f or \"png\" in f]\n            for f in fichiers:\n                if dir in dataset.keys():\n                    dataset[dir].append(f)\n                else:\n                    dataset[dir] = [f]\n        return dataset\n        # with open(os.path.join(dataset_path, 'list.txt'), 'r') as f:\n        #     dataset = {}\n        #     image_list = f.read().split()\n        #     for image in image_list:\n        #         folder_name, file_name = image.split('/')\n        #         if folder_name in dataset.keys():\n        #             dataset[folder_name].append(file_name)\n        #         else:\n        #             dataset[folder_name] = [file_name]\n        # return dataset\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            keys = list(self.dataset.keys())\n            random.shuffle(keys)\n            dataset_ =  {}\n            for key in keys:\n                dataset_[key] = self.dataset[key]\n            self.dataset = dataset_\n            \n    def get_image(self, person, index):\n        # print(os.path.join(self.dataset_path, os.path.join('images/' + person, self.dataset[person][index])))\n        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        # faces = self.face_detector.detectMultiScale(gray, 1.3, 5)\n        # try:\n        #     (x,y,w,h) = faces[0]\n        #     img = img[y:y+h, x:x+w]\n        # except:\n        #     pass\n        \n        img = cv2.imread(os.path.join(self.dataset_path, os.path.join(person, self.dataset[person][index])))\n        img = cv2.resize(img, (224, 224))\n        img = np.asarray(img, dtype=np.float64)\n        img = preprocess_input(img)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:14:03.3523Z","iopub.execute_input":"2022-03-17T15:14:03.352563Z","iopub.status.idle":"2022-03-17T15:14:03.374362Z","shell.execute_reply.started":"2022-03-17T15:14:03.352532Z","shell.execute_reply":"2022-03-17T15:14:03.373647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K = tf.keras.backend\ndef loss_function(x, alpha = 0.2):\n    # Triplet Loss function.\n    anchor,positive,negative = x\n    # distance between the anchor and the positive\n    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n    # distance between the anchor and the negative\n    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n    # compute loss\n    basic_loss = pos_dist-neg_dist+alpha\n    loss = K.mean(K.maximum(basic_loss,0.0))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:15:16.553123Z","iopub.execute_input":"2022-03-17T15:15:16.553405Z","iopub.status.idle":"2022-03-17T15:15:16.561079Z","shell.execute_reply.started":"2022-03-17T15:15:16.553372Z","shell.execute_reply":"2022-03-17T15:15:16.55848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vggface = tf.keras.models.Sequential()\n# vggface.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu', padding=\"SAME\", input_shape=(224,224, 3)))\n# vggface.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n \n# vggface.add(tf.keras.layers.Convolution2D(128, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(128, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n \n# vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(256, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n \n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n \n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.Convolution2D(512, (3, 3), activation='relu', padding=\"SAME\"))\n# vggface.add(tf.keras.layers.MaxPooling2D((2,2), strides=(2,2)))\n\n# vggface.add(tf.keras.layers.Flatten())\n\n# vggface.add(tf.keras.layers.Dense(4096, activation='relu'))\n# vggface.add(tf.keras.layers.Dropout(0.5))\n# vggface.add(tf.keras.layers.Dense(4096, activation='relu'))\n# vggface.add(tf.keras.layers.Dropout(0.5))\n# vggface.add(tf.keras.layers.Dense(2622, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:13:07.666909Z","iopub.status.idle":"2022-03-17T15:13:07.674133Z","shell.execute_reply.started":"2022-03-17T15:13:07.673886Z","shell.execute_reply":"2022-03-17T15:13:07.673913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n\ndef vgg_face():\t\n    model = Sequential()\n    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(256, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Convolution2D(512, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n    \n    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Convolution2D(2622, (1, 1)))\n    model.add(Flatten())\n    model.add(Activation('softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:13:24.792014Z","iopub.execute_input":"2022-03-17T15:13:24.792778Z","iopub.status.idle":"2022-03-17T15:13:24.813331Z","shell.execute_reply.started":"2022-03-17T15:13:24.792738Z","shell.execute_reply":"2022-03-17T15:13:24.81243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.applications.vgg16 import VGG16\n\n# # load model\n# model = VGG16()\n# # remove the output layer\n# model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n# # model.pop()\n# # add new classifier layers\n# x = layers.Dense(1024, activation='relu')(model.layers[-1].output)\n# x = layers.Dropout(0.5)(x)\n# x = layers.Dense(1024//2, activation='relu')(x)\n# x = layers.Dropout(0.5)(x)\n# output = Dense(128, use_bias=False)(x)\n# # define new model\n# model = Model(inputs=model.inputs, outputs=output)\n# for layer in model.layers[:-5]:\n#     layer.trainable = False\n\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:28:26.652452Z","iopub.execute_input":"2022-03-16T16:28:26.652953Z","iopub.status.idle":"2022-03-16T16:28:26.658888Z","shell.execute_reply.started":"2022-03-16T16:28:26.652913Z","shell.execute_reply":"2022-03-16T16:28:26.65798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = vgg_face()\nmodel.load_weights('../input/weights/vgg_face_weights.h5')\nmodel.pop()\n# model.add(tf.keras.layers.Dense(512))\n# model.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(2*512))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(128, use_bias=False, name='output'))\nfor layer in model.layers[:-3]:\n    layer.trainable = False\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:13:26.669381Z","iopub.execute_input":"2022-03-17T15:13:26.669632Z","iopub.status.idle":"2022-03-17T15:13:35.448275Z","shell.execute_reply.started":"2022-03-17T15:13:26.669603Z","shell.execute_reply":"2022-03-17T15:13:35.447587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SiameseNetwork(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:13:38.194011Z","iopub.execute_input":"2022-03-17T15:13:38.194588Z","iopub.status.idle":"2022-03-17T15:13:38.203772Z","shell.execute_reply.started":"2022-03-17T15:13:38.194551Z","shell.execute_reply":"2022-03-17T15:13:38.202989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.00006)\n#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00006)\n#binary_cross_entropy = tf.keras.losses.BinaryCrossentropy()\ndef train(X):\n    with tf.GradientTape() as tape:\n        y_pred = model(X)\n        loss = loss_function(y_pred)\n    grad = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grad, model.trainable_variables))\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:27:15.973683Z","iopub.execute_input":"2022-03-17T15:27:15.973956Z","iopub.status.idle":"2022-03-17T15:27:15.980468Z","shell.execute_reply.started":"2022-03-17T15:27:15.973924Z","shell.execute_reply":"2022-03-17T15:27:15.979283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save_weights('my_model.h5')\n# model.built = True\n# model.load_weights('my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T14:07:54.506429Z","iopub.execute_input":"2022-03-16T14:07:54.50697Z","iopub.status.idle":"2022-03-16T14:07:55.603798Z","shell.execute_reply.started":"2022-03-16T14:07:54.506933Z","shell.execute_reply":"2022-03-16T14:07:55.603029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/train/', batch_size=10)\n\n\nlosses = []\naccuracy = []\nepochs = 30\nno_of_batches = data_generator.__len__()\nprint(no_of_batches)\nfor i in range(1, epochs+1, 1):\n#     if i % 10 == 0:\n#         checkpoint.save(checkpoint_path)\n#         print(\"Checkpoint Saved\")\n    loss = 0\n    with tqdm(total=no_of_batches) as pbar:\n        \n        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n        pbar.set_description_str(description)\n        \n        for j in range(no_of_batches):\n            data = data_generator[j]\n            temp = train(data)\n            loss += temp\n            \n            pbar.update()\n            print_statement = \"Loss :\" + str(temp.numpy())\n            pbar.set_postfix_str(print_statement)\n        \n        loss /= no_of_batches\n        losses.append(loss.numpy())\n        # with file_writer.as_default():\n        #     tf.summary.scalar('Loss', data=loss.numpy(), step=i)\n            \n        print_statement = \"Loss :\" + str(loss.numpy())\n        \n        pbar.set_postfix_str(print_statement)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:27:28.181956Z","iopub.execute_input":"2022-03-17T15:27:28.182672Z","iopub.status.idle":"2022-03-17T15:33:31.446672Z","shell.execute_reply.started":"2022-03-17T15:27:28.182634Z","shell.execute_reply":"2022-03-17T15:33:31.445937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.get_layer('output').get_weights()[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T16:40:16.827912Z","iopub.execute_input":"2022-03-16T16:40:16.828202Z","iopub.status.idle":"2022-03-16T16:40:16.856046Z","shell.execute_reply.started":"2022-03-16T16:40:16.828171Z","shell.execute_reply":"2022-03-16T16:40:16.855018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"data_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/train/')\ntrain_dict = data_generator.curate_dataset('../input/dataset6/dataset4/train/')\nlabels = []\nfeatures = []\n\ni = 0\nfor k, v in train_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/dataset6/dataset4/train/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        images.append(image)\n\n    \n    images = np.asarray(images)\n    images = preprocess_input(images)\n    images = tf.convert_to_tensor(images)\n    feature = model.get_features(images)\n    feature = tf.reduce_mean(feature, axis=0)\n    features.append(feature.numpy())\n    labels.append(k)\n    \nfeatures = np.asarray(features)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:33:31.448385Z","iopub.execute_input":"2022-03-17T15:33:31.44879Z","iopub.status.idle":"2022-03-17T15:33:59.542393Z","shell.execute_reply.started":"2022-03-17T15:33:31.448752Z","shell.execute_reply":"2022-03-17T15:33:59.541624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_generator = DataGenerator(dataset_path='../input/dataset6/dataset4/test/')\ntest_dict = data_generator.curate_dataset('../input/dataset6/dataset4/test/')\n\nlabels_test = []\nimages_test = []\ni = 0\nfor k, v in test_dict.items():\n    for e in v:\n        image_path = '../input/dataset6/dataset4/test/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        images_test.append(image)\n        labels_test.append(k)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:33:59.543679Z","iopub.execute_input":"2022-03-17T15:33:59.543935Z","iopub.status.idle":"2022-03-17T15:34:01.05118Z","shell.execute_reply.started":"2022-03-17T15:33:59.543901Z","shell.execute_reply":"2022-03-17T15:34:01.050396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfeatures, labels = shuffle(features, labels)\nimages_test, labels_test = shuffle(images_test, labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.053333Z","iopub.execute_input":"2022-03-17T15:34:01.053595Z","iopub.status.idle":"2022-03-17T15:34:01.058815Z","shell.execute_reply.started":"2022-03-17T15:34:01.053561Z","shell.execute_reply":"2022-03-17T15:34:01.058157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(images):\n    preds = []\n    for image in images:\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        dist = tf.norm(img_features - features, axis=1)\n        preds.append(labels[tf.argmin(dist)])\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.059847Z","iopub.execute_input":"2022-03-17T15:34:01.060436Z","iopub.status.idle":"2022-03-17T15:34:01.069788Z","shell.execute_reply.started":"2022-03-17T15:34:01.060399Z","shell.execute_reply":"2022-03-17T15:34:01.06895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy\nfrom sklearn.metrics import accuracy_score\npreds = predict(images_test)\naccuracy_score(preds, labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:01.073024Z","iopub.execute_input":"2022-03-17T15:34:01.07327Z","iopub.status.idle":"2022-03-17T15:34:20.625511Z","shell.execute_reply.started":"2022-03-17T15:34:01.073228Z","shell.execute_reply":"2022-03-17T15:34:20.624874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.image as mpimg\nimage_path = '../input/dataset5/dataset3/test/Adílio/Adílio17.jpeg'\nplt.imshow(mpimg.imread(image_path))\nimage = cv2.imread(image_path)\nimage = np.asarray(image, dtype=np.float64)\npredict([image])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T09:38:40.835664Z","iopub.execute_input":"2022-03-15T09:38:40.835969Z","iopub.status.idle":"2022-03-15T09:38:41.112947Z","shell.execute_reply.started":"2022-03-15T09:38:40.835926Z","shell.execute_reply":"2022-03-15T09:38:41.112244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"train_dict = data_generator.curate_dataset('../input/dataset6/dataset4/train/')\nlabels_train = []\nfeatures_train = []\n\nfor k, v in train_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/dataset6/dataset4/train/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        features_train.append(img_features[0].numpy())\n        labels_train.append(k)\n\n    \n\nfeatures_train = np.asarray(features_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:34:20.62929Z","iopub.execute_input":"2022-03-17T15:34:20.631274Z","iopub.status.idle":"2022-03-17T15:36:24.392906Z","shell.execute_reply.started":"2022-03-17T15:34:20.631234Z","shell.execute_reply":"2022-03-17T15:36:24.392188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dict = data_generator.curate_dataset('../input/dataset6/dataset4/test/')\nlabels_test = []\nfeatures_test = []\n\nfor k, v in test_dict.items():\n    images = []\n    for e in v:\n        image_path = '../input/dataset6/dataset4/test/' + str(k) + '/' + str(e)\n        image = cv2.imread(image_path)\n        image = np.asarray(image, dtype=np.float64)\n        image = preprocess_input(image)\n        img_features = model.get_features(np.expand_dims(image, axis=0))\n        features_test.append(img_features[0].numpy())\n        labels_test.append(k)\n\n    \nfeatures_test = np.asarray(features_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:36:24.394321Z","iopub.execute_input":"2022-03-17T15:36:24.394566Z","iopub.status.idle":"2022-03-17T15:36:45.090399Z","shell.execute_reply.started":"2022-03-17T15:36:24.394533Z","shell.execute_reply":"2022-03-17T15:36:45.089654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfeatures_train, labels_train = shuffle(features_train, labels_train)\nfeatures_test, labels_test = shuffle(features_test, labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:36:45.091574Z","iopub.execute_input":"2022-03-17T15:36:45.091816Z","iopub.status.idle":"2022-03-17T15:36:45.100206Z","shell.execute_reply.started":"2022-03-17T15:36:45.091785Z","shell.execute_reply":"2022-03-17T15:36:45.099492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\ntuned_parameters = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n\n#clf = GridSearchCV(SVC(), tuned_parameters)\nclf = SVC(C=10, gamma=1)\nclf.fit(features_train, labels_train)\n\n# print(\"Best parameters set found on development set:\")\n# print()\n# print(clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:36:45.102792Z","iopub.execute_input":"2022-03-17T15:36:45.103206Z","iopub.status.idle":"2022-03-17T15:36:46.554568Z","shell.execute_reply.started":"2022-03-17T15:36:45.103144Z","shell.execute_reply":"2022-03-17T15:36:46.553853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npreds = clf.predict(features_test)\nprint(\"Accuracy :  \", accuracy_score(labels_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T15:36:46.555684Z","iopub.execute_input":"2022-03-17T15:36:46.555941Z","iopub.status.idle":"2022-03-17T15:36:47.54922Z","shell.execute_reply.started":"2022-03-17T15:36:46.555906Z","shell.execute_reply":"2022-03-17T15:36:47.548424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random forest","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:09:17.662258Z","iopub.execute_input":"2022-03-11T09:09:17.662522Z","iopub.status.idle":"2022-03-11T09:09:17.670724Z","shell.execute_reply.started":"2022-03-11T09:09:17.662493Z","shell.execute_reply":"2022-03-11T09:09:17.669951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(labels_train)\nencoded_labels_train = le.transform(labels_train)\nencoded_labels_test = le.transform(labels_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:09:20.852062Z","iopub.execute_input":"2022-03-11T09:09:20.852556Z","iopub.status.idle":"2022-03-11T09:09:20.859284Z","shell.execute_reply.started":"2022-03-11T09:09:20.852504Z","shell.execute_reply":"2022-03-11T09:09:20.858522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nclf_random.fit(features_train, encoded_labels_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:09:26.189064Z","iopub.execute_input":"2022-03-11T09:09:26.189374Z","iopub.status.idle":"2022-03-11T09:11:16.156414Z","shell.execute_reply.started":"2022-03-11T09:09:26.189337Z","shell.execute_reply":"2022-03-11T09:11:16.15561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clf_random.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:18:30.969702Z","iopub.execute_input":"2022-03-11T09:18:30.970497Z","iopub.status.idle":"2022-03-11T09:18:30.975873Z","shell.execute_reply.started":"2022-03-11T09:18:30.970448Z","shell.execute_reply":"2022-03-11T09:18:30.975051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npreds = clf_random.predict(features_test)\nprint(\"Accuracy :  \", accuracy_score(encoded_labels_test, preds))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T09:18:34.6348Z","iopub.execute_input":"2022-03-11T09:18:34.635274Z","iopub.status.idle":"2022-03-11T09:18:34.885212Z","shell.execute_reply.started":"2022-03-11T09:18:34.635239Z","shell.execute_reply":"2022-03-11T09:18:34.884413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}